{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3d58831-38b0-45b8-81ba-eaf26ae9a044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-15 22:09:46.986284: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S a ome b b b b b b b ThING to eat eat eat !', 'th aa some eat eat thing to drink .']\n",
      "OrderedDict([('s', 1), ('a', 1), ('ome', 1), ('b', 7), ('thing', 2), ('to', 2), ('eat', 5), ('th', 1), ('aa', 1), ('some', 1), ('drink', 1)])\n",
      "{'b': 1, 'eat': 2, 'thing': 3, 'to': 4, 's': 5, 'a': 6, 'ome': 7, 'th': 8, 'aa': 9, 'some': 10, 'drink': 11}\n",
      "[[5, 6, 7, 1, 1, 1, 1, 1, 1, 1, 3, 4, 2, 2, 2], [8, 9, 10, 2, 2, 3, 4, 11]]\n",
      "Found 11 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "text1='S a ome b b b b b b b ThING to eat eat eat !'\n",
    "text2='th aa some eat eat thing to drink .'\n",
    "texts=[text1,text2]\n",
    "print(texts)\n",
    "#out:['Some ThING to eat !', 'some thing to drink .']\n",
    "tokenizer = Tokenizer(num_words=100) #num_words:None或整数,处理的最大单词数量。少于此数的单词丢掉\n",
    "tokenizer.fit_on_texts(texts)\n",
    "print( tokenizer.word_counts) \n",
    "#out:OrderedDict([('some', 2), ('thing', 2), ('to', 2), ('eat', 1), ('drink', 1)])\n",
    "print( tokenizer.word_index) \n",
    "#out:{'some': 1, 'thing': 2, 'to': 3, 'eat': 4, 'drink': 5}\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print(sequences)\n",
    "#out:[[1, 2, 3, 4], [1, 2, 3, 5]] 转换为序列，注意这里句子等长，所以输出一样，但是不等长句子输出的长度是不一样的\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "#out:Found 5 unique tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c07ff0-c9cc-4e61-986c-3d3cc1afda03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing import sequence\n",
    "data = sequence.pad_sequences(sequences, maxlen=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe8f2031-8044-48ca-90da-7efbac68aa52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4,  2,  2,  2],\n",
       "       [ 2,  2,  3,  4, 11]], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015702df-823c-4a1b-b00a-fb786c233b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 6, 7, 1, 1, 1, 1, 1, 1, 1, 3, 4, 2, 2, 2], [8, 9, 10, 2, 2, 3, 4, 11]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad50de6-83bf-4ac8-be15-4f9cdb8292f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 1,\n",
       " 'eat': 2,\n",
       " 'thing': 3,\n",
       " 'to': 4,\n",
       " 's': 5,\n",
       " 'a': 6,\n",
       " 'ome': 7,\n",
       " 'th': 8,\n",
       " 'aa': 9,\n",
       " 'some': 10,\n",
       " 'drink': 11}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1228fc24-c89e-4745-bd47-668473733dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
